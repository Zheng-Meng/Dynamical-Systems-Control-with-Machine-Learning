<h1 align="center">Dynamical Systems Control with Machine Learning</h1>

Previously I have published a paper in [Nature Communications](https://doi.org/10.1038/s41467-023-41379-3), which proposed a framework to control dynamical systems, specifically robotic arms, to track complex chaotic or periodic trajectories. The codes are available in [My Github](https://github.com/Zheng-Meng/Tracking-Control). However, that is a complicated issue: it is not easy to train. At that time we trained at least hundreds of reservoirs using long training data.

Many people asked me that they are interested in this field (model-free control of dynamical systems with machine learning), and wonder if there exists a comparably simpler task for beginners to start with. In light of this, here I want to introduce controlling chaotic systems, specifically a chaotic Lorenz system to a periodic orbit, by using reservoir computing (a type of recurrent neural network). This task has been done in this [Paper](https://iopscience.iop.org/article/10.1088/2632-072X/ac24f3) (though there are some differences).

<h3>Overview</h3>

<p align="center">
<img src='figures/overview.png' width='800'>
</p>

This line of researh follows the above framework. Specifically, we first need to generate the training data, where the current state **x**(t) is driven by some control signal **u**(t) to the next state **x**(t+dt), step by step. You can imagine a robotic arm as an example: torques are added to the arms to push them move in time. After collecting this data, we would, as panel (a) depicts, put the current state and the next state together as the input, and the control signal that causes this as the output. Thus, the machine learns through the training phase: if we want to move from the current state to a nearby next state, how should we add the control signal to the system.

This is exactly how we test the model later. We give the current observed state **x**(t) and the target state **x**$_d(t)$ in each step as input, and the well-trained model should return an appropriate control signal. It is worth noting that this data-driven control framework is not only limited to chaotic orbit control or robotic arms; as long as it is a dynamical system, it should work.

<h3>Example: Controlling the Lorenz System</h3>

Now letâ€™s move to our example. Our aim here is to control a chaotic Lorenz system to a periodic orbit. 

First, run `find_lorenz_orbits.m` to identify periodic orbits for control and save them to a file for later use. Since I have already run this step and saved the results, you may skip it if desired. Below, I plot one of the identified orbits as an example:

<p align="center">
<img src='figures/lorenz_orbit.png' width='500'>
</p>

The black attractor is the Lorenz attractor, and the red line denotes one orbit that we will later control the system to follow. We choose the following method to add control signals to the Lorenz system:

$$\frac{dx}{dt}=\sigma (y-x) + u_1, $$

$$\frac{dy}{dt}=x(\rho - z) - y + u_2,$$

$$\frac{dz}{dt}=xy-\beta z + u_3,$$

where $$x, y, z$$ are the variables, and $$\sigma, \rho, \beta$$ are system parameters. The control signals **u**$$=(u_1, u_2, u_3)$$ are added to the equation to perturb the dynamics.

Following the framework introduced above, we first train a reservoir computing model to predict the control signals given the current and next states. Notably, the control signals are chosen within a specific range, generated by Gaussian noise and then smoothed. The control signals, as well as the time series affected by them, are shown below:

<p align="center">
<img src='figures/control_signal.png' width='800'>
</p>

Given this data, we can then train the machine learning controller. Here we use reservoir computing (RC) to serve as the controller.  As I already provided a detailed introduction about reservoir computing, if you are interested, you can take a look [here](https://github.com/Zheng-Meng/Reservoir-Computing-and-Hyperparameter-Optimization).

Run `train_rc_lorenz.m` to train the RC. After training, we evaluate the performance on the validation set, that is, we predict the control signal given current and next state, following the order on the attractor:

<p align="center">
<img src='figures/rc_train.png' width='700'>
</p>

The evaluation stage performance is great. However, this does not directly mean for target orbit it will predict well, as the target is conitinuous control to a periodic orbit. Therefore we need to further test the trained RC. Run `test_rc_lorenz` and it will use the saved trained RC, and test on pre-found orbit. One ran example are shown below:

<p align="center">
<img src='figures/controlled.png' width='700'>
</p>

On the left is the control signal generated by reservoir computing, where they are limited in the bound set in the training, even though the RC predicts a value out of bound. The controlled time series, compared with the ground truth target, are shown on the right. It can be seen that the RC tracks the target periodic orbit well visually. If we plot this tracked performance in 3 diemsional, the performance are as follows:

<p align="center">
<img src='figures/controlled_attractor.png' width='700'>
</p>

On the left is plot from the start, and on the right is what we remove the begining not stable control, and only plot long-term stable controlled result. The performance is that it also achieve stable tracks the orbit, although there are deviations that are not obvious in previous plot.

To further improve the performance, one should optimize the hyperparameters of RC, as they are vital to the performance, as shown in [here](https://github.com/Zheng-Meng/Reservoir-Computing-and-Hyperparameter-Optimization). In addition, you can do more test, such as longer or shorter periodic orbits, or control it to some unstable steady states, and others.

It is also worth noting that, one problem exist in many papers, and as also shown here, is that the control signals should be sufficiently large, to achieve a good peroframned control. However, in many real scenarios our energy is not enough. Then how to use as less as the control signals, in all aspects, to achieve a satisfactory ctonrl is a interesting topic.












