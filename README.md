<h1 align="center">Dynamical Systems Control with Machine Learning</h1>

Previously I have published a paper in [Nature Communications](https://doi.org/10.1038/s41467-023-41379-3), which proposed a framework to control dynamical systems, specifically, robotic arms, to track complex chaotic or periodic trajectories. The codes are available in [My Github](https://github.com/Zheng-Meng/Tracking-Control). However, I have to say that it is a complicated issue. It is not easy to train, at that time we trained at least hunderds of reservoirs in long traning data. Many asked me that they are interested in this field: Model-free control of dynamical systems with machine learning, and wonder that is there exist a comparably simpler task for beginning learn. In light of this, here I want to introduce controling chaotic systems, specifcally, a chaotic Lorenz system to a periodic orbit, by using reseroivr computing, which is a type of recurrent neural networks. I have to mention that this task has been done, in this [paper](https://iopscience.iop.org/article/10.1088/2632-072X/ac24f3), thus this repo is actually reproduce (although many things are simplfied here) that work.

Before that, I have to mention both these two works, in this line of researh, follow the similar framework (as shown in the figure above). Specifically, we need to first generate the training data, where the current state is drived by some control signal to the next state, step by step. You can imagine a robtic arm as an example: torques are added to the arms to push them move in time. After collecting this data, we would, as panel (a) depicts, put current state and the next state in each time together as the input, and the control singal cause this as the output. Thus the machine learns through the whole learning phase, if we want to start from the current state to a random next state (close), how should we add the control signal to the dynamical system. And this is exactly how we test the machine in the testing phase, we give current observed state, and the target state in each step as input, the well-trained machine should return an appropriate control signal. It is worth noting that this data driven control framework is not only limited in chaotic orbits control or robotic arms, as long as it is a dynamical system, it should work.

Now let's move to our example. Our aim is to control a chaotic Lorenz system, to a periodic orbit. If we can achieve this, and with more experiments, maybe we can successfully control this dynamical system to any state in the attractors (unstable steady states or arbitrary periodic orbits).

First, run `find_lorenz_orbits.m` then it can help you find orbits to control, and save them to file. I plot one of orbits found as an example:

<p align="center">
<img src='figures/lorenz_orbit.png' width='500'>
</p>

where the black attractor is the Lorenz attractor, and the red line denote on orbit that we would later control the dynamical system to follow.

We choose the following method to add control signals to the Lorenz system:

(Lorenz system formula here)

where x, y, z are the variabels, and rho, sigma, beta are default values (). The control signals (u1, u2, u3) are added to the three ODEs, separately.

Follow the framework we have introduced above, we would first train a reservoir computing, to predict accurately the control signals, given current and next states. Notably, the control signals are chosen in specific range, generated by Gaussian noise and being smoothed. The control singals, as well as the time series generated affected by the control signals, are shown as follows:

<p align="center">
<img src='figures/control_signal.png' width='800'>
</p>

Although I use different colors for each control signal and variable, please remember that each control signal affect the whole dynamics. 

Given this data, we can then train the RC, you can run `train_rc_lorenz.m` to train the RC. As I already provide a quite detiled introduction about reservoir computing, if you are interesed, you can take a look [here](https://github.com/Zheng-Meng/Reservoir-Computing-and-Hyperparameter-Optimization). After training, we will evalute the performacne on the validation set, that is, we just predict the control signal, by given current state and next state:

<p align="center">
<img src='figures/rc_train.png' width='700'>
</p>

The evaluation stage performance is great. However, this does not directly mean for target orbit it will predict well, as the target is conitinuous control to a periodic orbit. Therefore we need to further test the trained RC. Run `test_rc_lorenz` and it will use the saved trained RC, and test on pre-found orbit. 


















